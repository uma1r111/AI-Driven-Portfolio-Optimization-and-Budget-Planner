************* Random Forest - Decision Tree Documentation *************

RF-DT_v1.ipynb
not so basic code for random forst built upon decision tree. 
1) def min_max_scaling
2) def scale_features
3) def create_sequences
are same as LSTM code and the file for feature engineering (LSTM_stock_feature_engineering.ipynb) is also used here
for importing the curated dataset which has all the features (close price, normalized volume, rsi, bollinger bands, MA)

*in this code RandomForestRegressor uses DecisionTreeRegressor
inside the RandomForestRegressor.fit() method, we are creating multiple instances of DecisionTreeRegressor
training each one on a bootstrapped subset of the original data storing them in the forest so
random forest is an ensemble of many decision trees

*each individual DecisionTreeRegressor is trained The Random Forest itself does not learn parameters 
it is just creating, training, and combining the predictions of multiple trees. 

*we are using 3 parameters in this code:
1) n_trees
2) max_depth
3) min_samples_split

i will also implement other parameters like
1) max_features for RF (number of features to consider at each split)
2) max_leaf_nodes for DT (to reduce complexity)

like def create_sequences in LSTM code in which we use seq_length=50 which represents that previous 50 days are used for training
here it is also being used in the same way but not entirely same (sliding window of 10 days into a single input vector)

*the issue with the code is this that when i used seq_length=10, the predicted stock price is really off from the actual price
i then used seq_length=20, the predicted stock price is now more accurate but till 175th time step, i dont know why

*for parameter tuning, i will use grid search to find the best parameters for the model, i still have to see how 
will we implement that here maybe loop the model and save the parameters in dict for certain number of iterations ?

but for now this basic code does the job 70%

RF-DT_v2.ipynb
i implemented max_features -> options = [None, "sqrt", "log2", 5, 10], for different parameters, diff max_features gave less MSE
but the issue is that RF-DT is not made for time series data, like for uptrend, it does capture the trend but when there are
complex patterns like higher highs/low, lower highs/lows, the model struggles to capture the data, predicting an almost constant value
with less variation. even if i make a robust model out of it, whenever i will input a new stock with complex pattern, i will
have to repeat this whole parameter tuning step again again to make the model robust. 