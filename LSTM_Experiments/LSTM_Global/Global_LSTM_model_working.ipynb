{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "rzYJKYVjJIyl",
        "outputId": "d932f2fa-47bf-4776-d6eb-80c6a5eedc79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d38ff512-4653-4576-a196-46a4ef8ccfab\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d38ff512-4653-4576-a196-46a4ef8ccfab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving combined_stock_features.csv to combined_stock_features.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Click \"Choose Files\" and select your products.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_data = pd.read_csv(io.BytesIO(uploaded['combined_stock_features.csv']))\n",
        "print(stock_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToqnnVuQmEn9",
        "outputId": "3e59aa71-939d-48a7-9f0e-fd35b28f6d33"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Date       Close        High         Low        Open      Volume  \\\n",
            "0     2023-10-18  174.560593  176.287938  173.835908  174.302490  54764400.0   \n",
            "1     2023-10-19  174.183365  176.546038  173.915325  174.759131  59302900.0   \n",
            "2     2023-10-20  171.622162  174.143675  171.383903  174.034474  64189300.0   \n",
            "3     2023-10-23  171.741257  172.743903  168.693587  169.666467  55980100.0   \n",
            "4     2023-10-24  172.178085  172.406408  170.202559  171.790924  43816600.0   \n",
            "...          ...         ...         ...         ...         ...         ...   \n",
            "4993  2023-12-22   97.674713   98.661906   97.588450   98.058084  12921800.0   \n",
            "4994  2023-12-26   97.895142   98.748153   97.875976   98.470205  16835100.0   \n",
            "4995  2023-12-27   97.435097   98.288108   97.128389   97.799302  14558800.0   \n",
            "4996  2023-12-28   96.026184   97.387168   95.968673   97.176310  16329300.0   \n",
            "4997  2023-12-29   95.824913   96.409555   95.479874   96.198704  17741400.0   \n",
            "\n",
            "            MA10        MA50       MA100       MA200        RSI  Norm_Volume  \\\n",
            "0     176.789267  176.410239  181.079683  167.505648  63.704014     0.944474   \n",
            "1     176.843867  176.360807  181.082329  167.758402  61.394100     1.023126   \n",
            "2     176.386223  176.264513  181.040825  167.991975  47.672613     1.103809   \n",
            "3     175.791582  176.169410  181.001007  168.232766  51.718194     0.961323   \n",
            "4     175.300186  176.049886  180.937402  168.453005  49.338942     0.752408   \n",
            "...          ...         ...         ...         ...        ...          ...   \n",
            "4993   96.670258   99.728154  103.023652  101.943890  48.316084     0.588664   \n",
            "4994   96.911786   99.599063  102.993497  101.930071  56.213457     0.776447   \n",
            "4995   97.257784   99.459252  102.955915  101.919742  59.937658     0.673882   \n",
            "4996   97.379505   99.263909  102.906317  101.900500  56.502621     0.758253   \n",
            "4997   97.226155   99.034909  102.849713  101.905095  51.694234     0.828160   \n",
            "\n",
            "      Bollinger_Upper  Bollinger_Lower  Log_Returns  Pct_Change Ticker  \\\n",
            "0          180.555614       167.865721    -0.007422   -0.007395   AAPL   \n",
            "1          180.589858       167.983366    -0.002163   -0.002161   AAPL   \n",
            "2          180.599879       167.783738    -0.014813   -0.014704   AAPL   \n",
            "3          180.531357       167.546500     0.000694    0.000694   AAPL   \n",
            "4          180.478180       167.746600     0.002540    0.002544   AAPL   \n",
            "...               ...              ...          ...         ...    ...   \n",
            "4993       100.445163        93.591178     0.001768    0.001769    XOM   \n",
            "4994       100.160125        93.701780     0.002254    0.002257    XOM   \n",
            "4995        99.815758        93.831458    -0.004710   -0.004699    XOM   \n",
            "4996        99.671202        93.769949    -0.014566   -0.014460    XOM   \n",
            "4997        99.444350        93.732272    -0.002098   -0.002096    XOM   \n",
            "\n",
            "      Adj Close  \n",
            "0           NaN  \n",
            "1           NaN  \n",
            "2           NaN  \n",
            "3           NaN  \n",
            "4           NaN  \n",
            "...         ...  \n",
            "4993        NaN  \n",
            "4994        NaN  \n",
            "4995        NaN  \n",
            "4996        NaN  \n",
            "4997        NaN  \n",
            "\n",
            "[4998 rows x 18 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvpFyqFiL3Z0",
        "outputId": "1d8e06c9-201e-4f7b-f538-1c0b536b1586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Date       Close        High         Low        Open      Volume  \\\n",
            "0     2023-10-18  174.560593  176.287938  173.835908  174.302490  54764400.0   \n",
            "1     2023-10-19  174.183365  176.546038  173.915325  174.759131  59302900.0   \n",
            "2     2023-10-20  171.622162  174.143675  171.383903  174.034474  64189300.0   \n",
            "3     2023-10-23  171.741257  172.743903  168.693587  169.666467  55980100.0   \n",
            "4     2023-10-24  172.178085  172.406408  170.202559  171.790924  43816600.0   \n",
            "...          ...         ...         ...         ...         ...         ...   \n",
            "4993  2023-12-22   97.674713   98.661906   97.588450   98.058084  12921800.0   \n",
            "4994  2023-12-26   97.895142   98.748153   97.875976   98.470205  16835100.0   \n",
            "4995  2023-12-27   97.435097   98.288108   97.128389   97.799302  14558800.0   \n",
            "4996  2023-12-28   96.026184   97.387168   95.968673   97.176310  16329300.0   \n",
            "4997  2023-12-29   95.824913   96.409555   95.479874   96.198704  17741400.0   \n",
            "\n",
            "            MA10        MA50       MA100       MA200        RSI  Norm_Volume  \\\n",
            "0     176.789267  176.410239  181.079683  167.505648  63.704014     0.944474   \n",
            "1     176.843867  176.360807  181.082329  167.758402  61.394100     1.023126   \n",
            "2     176.386223  176.264513  181.040825  167.991975  47.672613     1.103809   \n",
            "3     175.791582  176.169410  181.001007  168.232766  51.718194     0.961323   \n",
            "4     175.300186  176.049886  180.937402  168.453005  49.338942     0.752408   \n",
            "...          ...         ...         ...         ...        ...          ...   \n",
            "4993   96.670258   99.728154  103.023652  101.943890  48.316084     0.588664   \n",
            "4994   96.911786   99.599063  102.993497  101.930071  56.213457     0.776447   \n",
            "4995   97.257784   99.459252  102.955915  101.919742  59.937658     0.673882   \n",
            "4996   97.379505   99.263909  102.906317  101.900500  56.502621     0.758253   \n",
            "4997   97.226155   99.034909  102.849713  101.905095  51.694234     0.828160   \n",
            "\n",
            "      Bollinger_Upper  Bollinger_Lower  Log_Returns  Pct_Change Ticker  \\\n",
            "0          180.555614       167.865721    -0.007422   -0.007395   AAPL   \n",
            "1          180.589858       167.983366    -0.002163   -0.002161   AAPL   \n",
            "2          180.599879       167.783738    -0.014813   -0.014704   AAPL   \n",
            "3          180.531357       167.546500     0.000694    0.000694   AAPL   \n",
            "4          180.478180       167.746600     0.002540    0.002544   AAPL   \n",
            "...               ...              ...          ...         ...    ...   \n",
            "4993       100.445163        93.591178     0.001768    0.001769    XOM   \n",
            "4994       100.160125        93.701780     0.002254    0.002257    XOM   \n",
            "4995        99.815758        93.831458    -0.004710   -0.004699    XOM   \n",
            "4996        99.671202        93.769949    -0.014566   -0.014460    XOM   \n",
            "4997        99.444350        93.732272    -0.002098   -0.002096    XOM   \n",
            "\n",
            "      Adj Close  \n",
            "0           NaN  \n",
            "1           NaN  \n",
            "2           NaN  \n",
            "3           NaN  \n",
            "4           NaN  \n",
            "...         ...  \n",
            "4993        NaN  \n",
            "4994        NaN  \n",
            "4995        NaN  \n",
            "4996        NaN  \n",
            "4997        NaN  \n",
            "\n",
            "[4998 rows x 18 columns]\n",
            "            Date       Close        High         Low        Open      Volume  \\\n",
            "0     2023-10-18  174.560593  176.287938  173.835908  174.302490  54764400.0   \n",
            "1     2023-10-19  174.183365  176.546038  173.915325  174.759131  59302900.0   \n",
            "2     2023-10-20  171.622162  174.143675  171.383903  174.034474  64189300.0   \n",
            "3     2023-10-23  171.741257  172.743903  168.693587  169.666467  55980100.0   \n",
            "4     2023-10-24  172.178085  172.406408  170.202559  171.790924  43816600.0   \n",
            "...          ...         ...         ...         ...         ...         ...   \n",
            "4993  2023-12-22   97.674713   98.661906   97.588450   98.058084  12921800.0   \n",
            "4994  2023-12-26   97.895142   98.748153   97.875976   98.470205  16835100.0   \n",
            "4995  2023-12-27   97.435097   98.288108   97.128389   97.799302  14558800.0   \n",
            "4996  2023-12-28   96.026184   97.387168   95.968673   97.176310  16329300.0   \n",
            "4997  2023-12-29   95.824913   96.409555   95.479874   96.198704  17741400.0   \n",
            "\n",
            "            MA10        MA50       MA100       MA200        RSI  Norm_Volume  \\\n",
            "0     176.789267  176.410239  181.079683  167.505648  63.704014     0.944474   \n",
            "1     176.843867  176.360807  181.082329  167.758402  61.394100     1.023126   \n",
            "2     176.386223  176.264513  181.040825  167.991975  47.672613     1.103809   \n",
            "3     175.791582  176.169410  181.001007  168.232766  51.718194     0.961323   \n",
            "4     175.300186  176.049886  180.937402  168.453005  49.338942     0.752408   \n",
            "...          ...         ...         ...         ...        ...          ...   \n",
            "4993   96.670258   99.728154  103.023652  101.943890  48.316084     0.588664   \n",
            "4994   96.911786   99.599063  102.993497  101.930071  56.213457     0.776447   \n",
            "4995   97.257784   99.459252  102.955915  101.919742  59.937658     0.673882   \n",
            "4996   97.379505   99.263909  102.906317  101.900500  56.502621     0.758253   \n",
            "4997   97.226155   99.034909  102.849713  101.905095  51.694234     0.828160   \n",
            "\n",
            "      Bollinger_Upper  Bollinger_Lower  Log_Returns  Pct_Change Ticker  \\\n",
            "0          180.555614       167.865721    -0.007422   -0.007395   AAPL   \n",
            "1          180.589858       167.983366    -0.002163   -0.002161   AAPL   \n",
            "2          180.599879       167.783738    -0.014813   -0.014704   AAPL   \n",
            "3          180.531357       167.546500     0.000694    0.000694   AAPL   \n",
            "4          180.478180       167.746600     0.002540    0.002544   AAPL   \n",
            "...               ...              ...          ...         ...    ...   \n",
            "4993       100.445163        93.591178     0.001768    0.001769    XOM   \n",
            "4994       100.160125        93.701780     0.002254    0.002257    XOM   \n",
            "4995        99.815758        93.831458    -0.004710   -0.004699    XOM   \n",
            "4996        99.671202        93.769949    -0.014566   -0.014460    XOM   \n",
            "4997        99.444350        93.732272    -0.002098   -0.002096    XOM   \n",
            "\n",
            "      Adj Close  \n",
            "0           NaN  \n",
            "1           NaN  \n",
            "2           NaN  \n",
            "3           NaN  \n",
            "4           NaN  \n",
            "...         ...  \n",
            "4993        NaN  \n",
            "4994        NaN  \n",
            "4995        NaN  \n",
            "4996        NaN  \n",
            "4997        NaN  \n",
            "\n",
            "[4998 rows x 18 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Read the uploaded file\n",
        "df = pd.read_csv(io.BytesIO(uploaded['combined_stock_features.csv']))\n",
        "print(df)\n",
        "\n",
        "# Or if you just want to save it first:\n",
        "with open('combined_stock_features.csv', 'wb') as f:\n",
        "    f.write(uploaded['combined_stock_features.csv'])\n",
        "\n",
        "df = pd.read_csv('combined_stock_features.csv')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "58rbigxyL6Tm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXzxPWQqMCZi"
      },
      "outputs": [],
      "source": [
        "# # Load the enhanced dataset\n",
        "# def load_enhanced_data(ticker=\"MSFT\"):\n",
        "#     df = pd.read_csv(f\"{ticker}_stock_features.csv\")\n",
        "#     df['Date'] = pd.to_datetime(df['Date'])  # Ensure Date is datetime\n",
        "#     df.set_index('Date', inplace=True)\n",
        "#     return df\n",
        "\n",
        "# ticker = \"MSFT\"\n",
        "# data = load_enhanced_data(ticker)\n",
        "# print(data.head())  # Verify all features are loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "874NpZVLpug4"
      },
      "outputs": [],
      "source": [
        "ticker_to_id = {ticker: idx for idx, ticker in enumerate(df['Ticker'].unique())}\n",
        "df['Ticker_ID'] = df['Ticker'].map(ticker_to_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oi8WkXezMHFR"
      },
      "outputs": [],
      "source": [
        "# Select features and target\n",
        "features = ['Close', 'MA100', 'RSI', 'Norm_Volume', 'Bollinger_Upper', 'Bollinger_Lower', 'Log_Returns', 'Ticker_ID']\n",
        "data = df[features]  # Keep only selected features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mQDJpNhJjMW6",
        "outputId": "71e67673-36c6-4176-c8fe-085aaa562445"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Close       MA100        RSI  Norm_Volume  Bollinger_Upper  \\\n",
              "0     174.560593  181.079683  63.704014     0.944474       180.555614   \n",
              "1     174.183365  181.082329  61.394100     1.023126       180.589858   \n",
              "2     171.622162  181.040825  47.672613     1.103809       180.599879   \n",
              "3     171.741257  181.001007  51.718194     0.961323       180.531357   \n",
              "4     172.178085  180.937402  49.338942     0.752408       180.478180   \n",
              "...          ...         ...        ...          ...              ...   \n",
              "4993   97.674713  103.023652  48.316084     0.588664       100.445163   \n",
              "4994   97.895142  102.993497  56.213457     0.776447       100.160125   \n",
              "4995   97.435097  102.955915  59.937658     0.673882        99.815758   \n",
              "4996   96.026184  102.906317  56.502621     0.758253        99.671202   \n",
              "4997   95.824913  102.849713  51.694234     0.828160        99.444350   \n",
              "\n",
              "      Bollinger_Lower  Log_Returns  Ticker_ID  \n",
              "0          167.865721    -0.007422          0  \n",
              "1          167.983366    -0.002163          0  \n",
              "2          167.783738    -0.014813          0  \n",
              "3          167.546500     0.000694          0  \n",
              "4          167.746600     0.002540          0  \n",
              "...               ...          ...        ...  \n",
              "4993        93.591178     0.001768         97  \n",
              "4994        93.701780     0.002254         97  \n",
              "4995        93.831458    -0.004710         97  \n",
              "4996        93.769949    -0.014566         97  \n",
              "4997        93.732272    -0.002098         97  \n",
              "\n",
              "[4998 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47331cc6-81ca-40fd-a067-3c30fd4aa8a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>MA100</th>\n",
              "      <th>RSI</th>\n",
              "      <th>Norm_Volume</th>\n",
              "      <th>Bollinger_Upper</th>\n",
              "      <th>Bollinger_Lower</th>\n",
              "      <th>Log_Returns</th>\n",
              "      <th>Ticker_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>174.560593</td>\n",
              "      <td>181.079683</td>\n",
              "      <td>63.704014</td>\n",
              "      <td>0.944474</td>\n",
              "      <td>180.555614</td>\n",
              "      <td>167.865721</td>\n",
              "      <td>-0.007422</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>174.183365</td>\n",
              "      <td>181.082329</td>\n",
              "      <td>61.394100</td>\n",
              "      <td>1.023126</td>\n",
              "      <td>180.589858</td>\n",
              "      <td>167.983366</td>\n",
              "      <td>-0.002163</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>171.622162</td>\n",
              "      <td>181.040825</td>\n",
              "      <td>47.672613</td>\n",
              "      <td>1.103809</td>\n",
              "      <td>180.599879</td>\n",
              "      <td>167.783738</td>\n",
              "      <td>-0.014813</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>171.741257</td>\n",
              "      <td>181.001007</td>\n",
              "      <td>51.718194</td>\n",
              "      <td>0.961323</td>\n",
              "      <td>180.531357</td>\n",
              "      <td>167.546500</td>\n",
              "      <td>0.000694</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>172.178085</td>\n",
              "      <td>180.937402</td>\n",
              "      <td>49.338942</td>\n",
              "      <td>0.752408</td>\n",
              "      <td>180.478180</td>\n",
              "      <td>167.746600</td>\n",
              "      <td>0.002540</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>97.674713</td>\n",
              "      <td>103.023652</td>\n",
              "      <td>48.316084</td>\n",
              "      <td>0.588664</td>\n",
              "      <td>100.445163</td>\n",
              "      <td>93.591178</td>\n",
              "      <td>0.001768</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>97.895142</td>\n",
              "      <td>102.993497</td>\n",
              "      <td>56.213457</td>\n",
              "      <td>0.776447</td>\n",
              "      <td>100.160125</td>\n",
              "      <td>93.701780</td>\n",
              "      <td>0.002254</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>97.435097</td>\n",
              "      <td>102.955915</td>\n",
              "      <td>59.937658</td>\n",
              "      <td>0.673882</td>\n",
              "      <td>99.815758</td>\n",
              "      <td>93.831458</td>\n",
              "      <td>-0.004710</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>96.026184</td>\n",
              "      <td>102.906317</td>\n",
              "      <td>56.502621</td>\n",
              "      <td>0.758253</td>\n",
              "      <td>99.671202</td>\n",
              "      <td>93.769949</td>\n",
              "      <td>-0.014566</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>95.824913</td>\n",
              "      <td>102.849713</td>\n",
              "      <td>51.694234</td>\n",
              "      <td>0.828160</td>\n",
              "      <td>99.444350</td>\n",
              "      <td>93.732272</td>\n",
              "      <td>-0.002098</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4998 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47331cc6-81ca-40fd-a067-3c30fd4aa8a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47331cc6-81ca-40fd-a067-3c30fd4aa8a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47331cc6-81ca-40fd-a067-3c30fd4aa8a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a7294795-6872-47ed-bfbf-a267c3fc6c0a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7294795-6872-47ed-bfbf-a267c3fc6c0a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a7294795-6872-47ed-bfbf-a267c3fc6c0a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d4c0e9d5-3861-497e-9e1a-ff601ecf97be\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d4c0e9d5-3861-497e-9e1a-ff601ecf97be button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 4998,\n  \"fields\": [\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 333.0975249838475,\n        \"min\": 8.706219673156738,\n        \"max\": 3528.076904296875,\n        \"num_unique_values\": 4902,\n        \"samples\": [\n          39.56974029541016,\n          46.6094970703125,\n          243.19937133789065\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MA100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 317.45391428953025,\n        \"min\": 10.3364444732666,\n        \"max\": 3085.581296386719,\n        \"num_unique_values\": 4997,\n        \"samples\": [\n          137.54954750061034,\n          139.38615447998046,\n          214.4697511291504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RSI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.03585363930511,\n        \"min\": 10.779365136691156,\n        \"max\": 100.0,\n        \"num_unique_values\": 4995,\n        \"samples\": [\n          82.64815164988258,\n          74.77840794907567,\n          62.276982555627406\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Norm_Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5242313916772985,\n        \"min\": 0.2075337685737106,\n        \"max\": 9.045167914734638,\n        \"num_unique_values\": 4998,\n        \"samples\": [\n          0.7832886299082324,\n          1.0509221324353717,\n          0.6039024898562617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bollinger_Upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 347.7254168849297,\n        \"min\": 9.653313289298826,\n        \"max\": 3664.1150921417466,\n        \"num_unique_values\": 4996,\n        \"samples\": [\n          136.7748528908655,\n          158.89575096306342,\n          207.28497833576665\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bollinger_Lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 300.07342142579785,\n        \"min\": 8.164175279090895,\n        \"max\": 3053.1867144988782,\n        \"num_unique_values\": 4996,\n        \"samples\": [\n          128.00458131323606,\n          141.05101112189752,\n          183.3870950284912\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Log_Returns\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016404397047590058,\n        \"min\": -0.1328242995193999,\n        \"max\": 0.1634301857969045,\n        \"num_unique_values\": 4976,\n        \"samples\": [\n          0.0102565070471002,\n          0.0071513002466407,\n          0.0005000146208018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticker_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 0,\n        \"max\": 97,\n        \"num_unique_values\": 98,\n        \"samples\": [\n          62,\n          40,\n          94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7B1D-B29MIKN"
      },
      "outputs": [],
      "source": [
        "def min_max_scaling(data):\n",
        "    \"\"\"Scale data to [0, 1] range and return scaled data + min/max values\"\"\"\n",
        "    min_val = np.min(data)\n",
        "    max_val = np.max(data)\n",
        "    # Handle case where all values are identical (avoid division by zero)\n",
        "    if max_val == min_val:\n",
        "        return np.zeros_like(data), min_val, max_val\n",
        "    return (data - min_val) / (max_val - min_val), min_val, max_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R1fDmlHWMJvB"
      },
      "outputs": [],
      "source": [
        "def scale_features(df):\n",
        "    \"\"\"Scale each feature column independently\"\"\"\n",
        "    scaled_data = {}\n",
        "    scalers = {}  # To store min/max for each feature\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col == 'Ticker_ID':\n",
        "            scaled_data[col] = df[col].values  # Keep as is (integer IDs)\n",
        "            continue\n",
        "\n",
        "        scaled_values, min_val, max_val = min_max_scaling(df[col].values)\n",
        "        if col == 'Log_Returns':\n",
        "            scalers['target'] = (min_val, max_val)\n",
        "        else:\n",
        "            scalers[col] = (min_val, max_val)\n",
        "\n",
        "        scaled_data[col] = scaled_values\n",
        "\n",
        "    return pd.DataFrame(scaled_data), scalers\n",
        "\n",
        "# Scale all features\n",
        "scaled_data, scalers = scale_features(data)\n",
        "\n",
        "# Split into train/test (keeping temporal order)\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(scaled_data) * split_ratio)\n",
        "train_data = scaled_data.iloc[:split_index]\n",
        "test_data = scaled_data.iloc[split_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGHXXjsMzRN1",
        "outputId": "3eb4f44e-3251-4c42-b5b7-4052766f27ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Close', 'MA100', 'RSI', 'Norm_Volume', 'Bollinger_Upper',\n",
            "       'Bollinger_Lower', 'Log_Returns', 'Ticker_ID'],\n",
            "      dtype='object')\n",
            "Index(['Close', 'MA100', 'RSI', 'Norm_Volume', 'Bollinger_Upper',\n",
            "       'Bollinger_Lower', 'Log_Returns', 'Ticker_ID'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(train_data.columns)\n",
        "print(test_data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eaeTYKXqxYXV"
      },
      "outputs": [],
      "source": [
        "# Create ticker mapping and ticker IDs\n",
        "unique_tickers = list(set(train_data['Ticker_ID'].values) | set(test_data['Ticker_ID'].values))\n",
        "ticker_mapping = {ticker: idx for idx, ticker in enumerate(unique_tickers)}\n",
        "\n",
        "train_ticker_ids = train_data['Ticker_ID'].values\n",
        "test_ticker_ids = test_data['Ticker_ID'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mymmI-pfMLbm",
        "outputId": "2c30b212-eb50-4d41-ab4e-80adef425c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training shapes - X: (78, 50, 6), y: (78,)\n",
            "Test shapes - X: (19, 50, 6), y: (19,)\n"
          ]
        }
      ],
      "source": [
        "def create_sequences_multi(data, ticker_ids, seq_length=50, target_col='Log_Returns'):\n",
        "    \"\"\"Create sequences from multiple features (without including Ticker_ID)\"\"\"\n",
        "    X, y, ticker_seq_list = [], [], []\n",
        "    data_values = data.drop(['Ticker_ID'], axis=1).values  # Drop 'Ticker_ID' from features\n",
        "\n",
        "    for ticker_id in np.unique(ticker_ids):\n",
        "        ticker_data = data[data['Ticker_ID'] == ticker_id]\n",
        "        features = ticker_data.drop(['Log_Returns', 'Ticker_ID'], axis=1).values\n",
        "        targets = ticker_data['Log_Returns'].values\n",
        "\n",
        "        for i in range(len(features) - seq_length):\n",
        "            # Create a sequence of features (X)\n",
        "            X.append(features[i:i+seq_length, :])  # Selecting only the features\n",
        "            # Append the corresponding ticker_id to the ticker_seq_list\n",
        "            ticker_seq_list.append(ticker_id)\n",
        "            # The target is the Log_Returns for the next time step\n",
        "            y.append(targets[i + seq_length])\n",
        "\n",
        "    return np.array(X), np.array(y), np.array(ticker_seq_list)\n",
        "\n",
        "# After fixing the sequence generation, create the sequences for train and test data\n",
        "X_train, y_train, train_tickers = create_sequences_multi(train_data, train_ticker_ids, seq_length)\n",
        "X_test, y_test, test_tickers = create_sequences_multi(test_data, test_ticker_ids, seq_length)\n",
        "\n",
        "# Check shapes\n",
        "print(f\"Training shapes - X: {X_train.shape}, y: {y_train.shape}\")\n",
        "print(f\"Test shapes - X: {X_test.shape}, y: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "ROZ8S4AnMNKO"
      },
      "outputs": [],
      "source": [
        "# Add Adam optimizer support in LSTM class\n",
        "\n",
        "class LSTM:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, ticker_dim, embedding_dim, learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.lr = learning_rate\n",
        "        self.ticker_dim = ticker_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.epsilon = epsilon\n",
        "        self.t = 1  # time step for Adam\n",
        "\n",
        "        # Combined input size: hidden + input + ticker embedding\n",
        "        concat_dim = hidden_dim + input_dim + embedding_dim\n",
        "\n",
        "        # Initialize weights\n",
        "        self.Wf = np.random.randn(hidden_dim, concat_dim) * 0.01\n",
        "        self.bf = np.zeros((hidden_dim, 1))\n",
        "\n",
        "        self.Wi = np.random.randn(hidden_dim, concat_dim) * 0.01\n",
        "        self.bi = np.zeros((hidden_dim, 1))\n",
        "\n",
        "        self.Wc = np.random.randn(hidden_dim, concat_dim) * 0.01\n",
        "        self.bc = np.zeros((hidden_dim, 1))\n",
        "\n",
        "        self.Wo = np.random.randn(hidden_dim, concat_dim) * 0.01\n",
        "        self.bo = np.zeros((hidden_dim, 1))\n",
        "\n",
        "        # Output layer\n",
        "        self.Wy = np.random.randn(output_dim, hidden_dim) * 0.01\n",
        "        self.by = np.zeros((output_dim, 1))\n",
        "\n",
        "        # Initialize embedding matrix for Ticker_ID\n",
        "        self.ticker_embedding = np.random.randn(self.ticker_dim, self.embedding_dim) * 0.01\n",
        "\n",
        "        # Initialize Adam moment estimates\n",
        "        self._init_adam_params()\n",
        "\n",
        "    def _init_adam_params(self):\n",
        "        self.m = {}\n",
        "        self.v = {}\n",
        "        for param_name in ['Wf', 'Wi', 'Wc', 'Wo', 'Wy', 'bf', 'bi', 'bc', 'bo', 'by']:\n",
        "            param = getattr(self, param_name)\n",
        "            self.m[param_name] = np.zeros_like(param)\n",
        "            self.v[param_name] = np.zeros_like(param)\n",
        "\n",
        "    def get_ticker_embedding(self, ticker_id):\n",
        "        \"\"\"Return the embedding for the ticker ID\"\"\"\n",
        "        return self.ticker_embedding[ticker_id].reshape(-1, 1)\n",
        "\n",
        "    def sigmoid(self, x): return 1 / (1 + np.exp(-x))\n",
        "    def dsigmoid(self, x): return x * (1 - x)\n",
        "    def tanh(self, x): return np.tanh(x)\n",
        "    def dtanh(self, x): return 1 - x ** 2\n",
        "\n",
        "\n",
        "    def forward(self, x_seq, ticker_id, h=None, c=None):\n",
        "\n",
        "      if h is None:\n",
        "          h = np.zeros((self.hidden_dim, 1))\n",
        "      if c is None:\n",
        "          c = np.zeros((self.hidden_dim, 1))\n",
        "      self.caches = []\n",
        "\n",
        "    # Get embedding once per sequence (not per timestep)\n",
        "      ticker_embedding = self.get_ticker_embedding(ticker_id).reshape(-1, 1)\n",
        "\n",
        "      for x in x_seq:\n",
        "          x = x.reshape(self.input_dim, 1)\n",
        "\n",
        "          # Concatenate previous hidden state, input, and ticker embedding\n",
        "          concat = np.vstack((h, x, ticker_embedding))\n",
        "\n",
        "          ft = self.sigmoid(np.dot(self.Wf, concat) + self.bf)\n",
        "          it = self.sigmoid(np.dot(self.Wi, concat) + self.bi)\n",
        "          c_tilde = self.tanh(np.dot(self.Wc, concat) + self.bc)\n",
        "          c = ft * c + it * c_tilde\n",
        "          ot = self.sigmoid(np.dot(self.Wo, concat) + self.bo)\n",
        "          h = ot * self.tanh(c)\n",
        "\n",
        "          self.caches.append((h, c, ft, it, c_tilde, ot, concat))\n",
        "\n",
        "      y_hat = np.dot(self.Wy, h) + self.by\n",
        "      return y_hat, h, c\n",
        "\n",
        "    def backward(self, x_seq, y_hat, y_true):\n",
        "        dh_next = np.zeros((self.hidden_dim, 1))\n",
        "        dc_next = np.zeros((self.hidden_dim, 1))\n",
        "\n",
        "        grads = {\n",
        "            'Wf': np.zeros_like(self.Wf), 'Wi': np.zeros_like(self.Wi),\n",
        "            'Wc': np.zeros_like(self.Wc), 'Wo': np.zeros_like(self.Wo),\n",
        "            'Wy': np.zeros_like(self.Wy),\n",
        "            'bf': np.zeros_like(self.bf), 'bi': np.zeros_like(self.bi),\n",
        "            'bc': np.zeros_like(self.bc), 'bo': np.zeros_like(self.bo),\n",
        "            'by': np.zeros_like(self.by)\n",
        "        }\n",
        "\n",
        "        dy = y_hat - y_true\n",
        "        grads['Wy'] += np.dot(dy, self.caches[-1][0].T)\n",
        "        grads['by'] += dy\n",
        "\n",
        "        dh = np.dot(self.Wy.T, dy) + dh_next\n",
        "\n",
        "        for t in reversed(range(len(x_seq))):\n",
        "            h, c, ft, it, c_tilde, ot, concat = self.caches[t]\n",
        "            c_prev = self.caches[t - 1][1] if t > 0 else np.zeros_like(c)\n",
        "\n",
        "            do = dh * self.tanh(c)\n",
        "            do_raw = do * self.dsigmoid(ot)\n",
        "\n",
        "            dc = dh * ot * self.dtanh(self.tanh(c)) + dc_next\n",
        "            dc_tilde = dc * it\n",
        "            dc_tilde_raw = dc_tilde * self.dtanh(c_tilde)\n",
        "\n",
        "            di = dc * c_tilde\n",
        "            di_raw = di * self.dsigmoid(it)\n",
        "\n",
        "            df = dc * c_prev\n",
        "            df_raw = df * self.dsigmoid(ft)\n",
        "\n",
        "            grads['Wf'] += np.dot(df_raw, concat.T)\n",
        "            grads['Wi'] += np.dot(di_raw, concat.T)\n",
        "            grads['Wc'] += np.dot(dc_tilde_raw, concat.T)\n",
        "            grads['Wo'] += np.dot(do_raw, concat.T)\n",
        "\n",
        "            grads['bf'] += df_raw\n",
        "            grads['bi'] += di_raw\n",
        "            grads['bc'] += dc_tilde_raw\n",
        "            grads['bo'] += do_raw\n",
        "\n",
        "            dconcat = (np.dot(self.Wf.T, df_raw) +\n",
        "                       np.dot(self.Wi.T, di_raw) +\n",
        "                       np.dot(self.Wc.T, dc_tilde_raw) +\n",
        "                       np.dot(self.Wo.T, do_raw))\n",
        "\n",
        "            dh = dconcat[:self.hidden_dim, :]\n",
        "            dc_next = dc * ft\n",
        "\n",
        "        self._apply_adam(grads)\n",
        "        self.t += 1  # Increment timestep\n",
        "\n",
        "    def _apply_adam(self, grads):\n",
        "        for param_name in grads:\n",
        "            grad = grads[param_name]\n",
        "            self.m[param_name] = self.beta1 * self.m[param_name] + (1 - self.beta1) * grad\n",
        "            self.v[param_name] = self.beta2 * self.v[param_name] + (1 - self.beta2) * (grad ** 2)\n",
        "\n",
        "            m_hat = self.m[param_name] / (1 - self.beta1 ** self.t)\n",
        "            v_hat = self.v[param_name] / (1 - self.beta2 ** self.t)\n",
        "\n",
        "            param = getattr(self, param_name)\n",
        "            param -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
        "            setattr(self, param_name, param)\n",
        "\n",
        "    def train(self, X_train, y_train, ticker_ids_train, epochs=10, batch_size=32):\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            indices = np.arange(len(X_train))\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "            for i in range(0, len(X_train), batch_size):\n",
        "                batch_indices = indices[i:i+batch_size]\n",
        "                batch_loss = 0\n",
        "                batch_grads = []\n",
        "\n",
        "                for j in batch_indices:\n",
        "                    x_seq = X_train[j]\n",
        "                    y_true = y_train[j].reshape(self.output_dim, 1)\n",
        "                    ticker_ids = ticker_ids_train[j]\n",
        "                    y_hat, _, _ = self.forward(x_seq, ticker_ids)\n",
        "                    loss = np.mean((y_hat - y_true) ** 2)\n",
        "                    batch_loss += loss\n",
        "\n",
        "                    self.backward(x_seq, y_hat, y_true)\n",
        "\n",
        "                total_loss += batch_loss\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-08sXxS9MOuO",
        "outputId": "64a8c919-54fc-4c2b-e828-debcc1dd8ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 10.906418\n",
            "Epoch 2/50, Loss: 1.597311\n",
            "Epoch 3/50, Loss: 0.169694\n",
            "Epoch 4/50, Loss: 0.096311\n",
            "Epoch 5/50, Loss: 0.066584\n",
            "Epoch 6/50, Loss: 0.059735\n",
            "Epoch 7/50, Loss: 0.055716\n",
            "Epoch 8/50, Loss: 0.045183\n",
            "Epoch 9/50, Loss: 0.052035\n",
            "Epoch 10/50, Loss: 0.045273\n",
            "Epoch 11/50, Loss: 0.044178\n",
            "Epoch 12/50, Loss: 0.042728\n",
            "Epoch 13/50, Loss: 0.035541\n",
            "Epoch 14/50, Loss: 0.047966\n",
            "Epoch 15/50, Loss: 0.034251\n",
            "Epoch 16/50, Loss: 0.035405\n",
            "Epoch 17/50, Loss: 0.031437\n",
            "Epoch 18/50, Loss: 0.034965\n",
            "Epoch 19/50, Loss: 0.040943\n",
            "Epoch 20/50, Loss: 0.032189\n",
            "Epoch 21/50, Loss: 0.027551\n",
            "Epoch 22/50, Loss: 0.026350\n",
            "Epoch 23/50, Loss: 0.028784\n",
            "Epoch 24/50, Loss: 0.028282\n",
            "Epoch 25/50, Loss: 0.028890\n",
            "Epoch 26/50, Loss: 0.028257\n",
            "Epoch 27/50, Loss: 0.027155\n",
            "Epoch 28/50, Loss: 0.030545\n",
            "Epoch 29/50, Loss: 0.026397\n",
            "Epoch 30/50, Loss: 0.025429\n",
            "Epoch 31/50, Loss: 0.024497\n",
            "Epoch 32/50, Loss: 0.021560\n",
            "Epoch 33/50, Loss: 0.022775\n",
            "Epoch 34/50, Loss: 0.025907\n",
            "Epoch 35/50, Loss: 0.020993\n",
            "Epoch 36/50, Loss: 0.027340\n",
            "Epoch 37/50, Loss: 0.021532\n",
            "Epoch 38/50, Loss: 0.024881\n",
            "Epoch 39/50, Loss: 0.022272\n",
            "Epoch 40/50, Loss: 0.019186\n",
            "Epoch 41/50, Loss: 0.018450\n",
            "Epoch 42/50, Loss: 0.019640\n",
            "Epoch 43/50, Loss: 0.022687\n",
            "Epoch 44/50, Loss: 0.018669\n",
            "Epoch 45/50, Loss: 0.019700\n",
            "Epoch 46/50, Loss: 0.024378\n",
            "Epoch 47/50, Loss: 0.024315\n",
            "Epoch 48/50, Loss: 0.019895\n",
            "Epoch 49/50, Loss: 0.017767\n",
            "Epoch 50/50, Loss: 0.018634\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train, train_tickers = create_sequences_multi(train_data, train_data['Ticker_ID'].values, seq_length)\n",
        "X_test, y_test, test_tickers = create_sequences_multi(test_data, test_data['Ticker_ID'].values, seq_length)\n",
        "\n",
        "lstm = LSTM(input_dim=X_train.shape[2], hidden_dim=128, output_dim=1,\n",
        "            ticker_dim=len(ticker_mapping), embedding_dim=32, learning_rate=0.001)\n",
        "\n",
        "lstm.train(X_train, y_train, train_tickers, epochs=50, batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "-9hWDXe2MQH5"
      },
      "outputs": [],
      "source": [
        "def predict_multi(lstm, X_test, test_tickers, scalers):\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(len(X_test)):\n",
        "        x_seq = X_test[i]\n",
        "        ticker_ids = test_tickers[i]\n",
        "        # Reinitialize h and c for stateless predictions\n",
        "        h_prev = np.zeros((lstm.hidden_dim, 1))\n",
        "        c_prev = np.zeros((lstm.hidden_dim, 1))\n",
        "        y_pred, _, _ = lstm.forward(x_seq, ticker_ids, h_prev, c_prev)\n",
        "        predictions.append(y_pred.flatten()[0])\n",
        "\n",
        "    # Inverse scale predictions\n",
        "    min_target, max_target = scalers['target']\n",
        "    predictions = np.array(predictions) * (max_target - min_target) + min_target\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_for_stock(lstm, stock_df, ticker, ticker_mapping, scalers, seq_length):\n",
        "    \"\"\"\n",
        "    Predict target for a specific stock using the last available sequence.\n",
        "    \"\"\"\n",
        "    # Get ticker ID from ticker_mapping\n",
        "    ticker_id = ticker_mapping[ticker]\n",
        "\n",
        "    # Merge stock_df with data to get the Ticker_ID\n",
        "    stock_df_with_ticker_id = stock_df.copy()  # Avoid modifying the original stock_df\n",
        "    stock_df_with_ticker_id['Ticker_ID'] = stock_df_with_ticker_id['Ticker'].map(ticker_mapping)\n",
        "\n",
        "    # Filter data for the specific stock\n",
        "    stock_data_filtered = stock_df_with_ticker_id[stock_df_with_ticker_id['Ticker'] == ticker]\n",
        "\n",
        "    # Ensure there's enough data for the sequence\n",
        "    if len(stock_data_filtered) < seq_length:\n",
        "        raise ValueError(f\"Not enough data for stock {ticker}. Need at least {seq_length} rows.\")\n",
        "\n",
        "    # Select only the features that the model expects (6 features)\n",
        "    required_columns = ['Close', 'MA100', 'RSI', 'Norm_Volume', 'Bollinger_Upper', 'Bollinger_Lower']\n",
        "    x_seq = stock_data_filtered[required_columns].iloc[-seq_length:].values\n",
        "\n",
        "    # Debugging: Check the shape of x_seq\n",
        "    print(f\"Shape of x_seq: {x_seq.shape}\")\n",
        "\n",
        "    # Ensure x_seq has the correct number of features (input_dim)\n",
        "    if x_seq.shape[1] != lstm.input_dim:\n",
        "        raise ValueError(f\"Shape mismatch! x_seq has {x_seq.shape[1]} features, but model expects {lstm.input_dim} features.\")\n",
        "\n",
        "    # Forward pass\n",
        "    h_prev = np.zeros((lstm.hidden_dim, 1))\n",
        "    c_prev = np.zeros((lstm.hidden_dim, 1))\n",
        "    y_pred, _, _ = lstm.forward(x_seq, ticker_id, h_prev, c_prev)\n",
        "\n",
        "    # Inverse scale\n",
        "    min_target, max_target = scalers['target']\n",
        "    prediction = y_pred.flatten()[0] * (max_target - min_target) + min_target\n",
        "\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "3HwJNvjzvZUP"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_N7YNCitdrH",
        "outputId": "e5a44bbf-2c34-4204-bbfb-3854552b6d30"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'MA10', 'MA50',\n",
              "       'MA100', 'MA200', 'RSI', 'Norm_Volume', 'Bollinger_Upper',\n",
              "       'Bollinger_Lower', 'Log_Returns', 'Pct_Change', 'Ticker', 'Adj Close'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4IxRZd0tlvZ",
        "outputId": "d3f7e04a-d89b-423b-dd58-02017e5f6225"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Close', 'MA100', 'RSI', 'Norm_Volume', 'Bollinger_Upper',\n",
              "       'Bollinger_Lower', 'Log_Returns', 'Ticker_ID'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a reverse mapping from Ticker to Ticker_ID using stock_data and data\n",
        "ticker_mapping = dict(zip(stock_data['Ticker'], data['Ticker_ID']))\n",
        "\n",
        "# Now, when you want to predict for a specific stock (e.g., 'AAPL')\n",
        "ticker = 'AAPL'\n",
        "\n",
        "# Get the Ticker_ID corresponding to the ticker (e.g., 'AAPL')\n",
        "ticker_id = ticker_mapping[ticker]\n",
        "\n",
        "# Now call the predict_for_stock function using the ticker symbol (not the ticker_id)\n",
        "predicted_value = predict_for_stock(lstm, stock_data, ticker, ticker_mapping, scalers, seq_length)\n",
        "\n",
        "# Print the predicted log_return/volatility for 'AAPL'\n",
        "print(f\"Predicted log_return/volatility for {ticker}: {predicted_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryUZKVrSpBMu",
        "outputId": "13ee8bb2-76df-4d66-ace7-a4e5a8d41a6e"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_seq: (50, 6)\n",
            "Predicted log_return/volatility for AAPL: -0.10116204814911275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_for_stock_over_time(lstm, stock_df, ticker, ticker_mapping, scalers, seq_length):\n",
        "    \"\"\"\n",
        "    Predict target (log_return/volatility) for every time step after the first seq_length\n",
        "    for a specific stock. Returns a list of predictions.\n",
        "    \"\"\"\n",
        "    # Get Ticker ID\n",
        "    ticker_id = ticker_mapping[ticker]\n",
        "\n",
        "    # Filter data for the stock\n",
        "    stock_data = stock_df[stock_df['Ticker'] == ticker].copy()\n",
        "\n",
        "    # Ensure enough data\n",
        "    if len(stock_data) < seq_length:\n",
        "        raise ValueError(f\"Not enough data for stock {ticker}. Need at least {seq_length} rows.\")\n",
        "\n",
        "    # Features used for input\n",
        "    feature_cols = ['Close', 'MA100', 'RSI', 'Norm_Volume',\n",
        "                    'Bollinger_Upper', 'Bollinger_Lower']  # Input_dim = 6\n",
        "\n",
        "    # Reset hidden state (optional: you can also keep it flowing if desired)\n",
        "    h_prev = np.zeros((lstm.hidden_dim, 1))\n",
        "    c_prev = np.zeros((lstm.hidden_dim, 1))\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    # Loop over all possible sequences\n",
        "    for i in range(len(stock_data) - seq_length):\n",
        "        x_seq = stock_data.iloc[i:i+seq_length][feature_cols].values\n",
        "\n",
        "        if x_seq.shape[1] != lstm.input_dim:\n",
        "            raise ValueError(f\"Shape mismatch! x_seq has {x_seq.shape[1]} features, but model expects {lstm.input_dim} features.\")\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred, h_prev, c_prev = lstm.forward(x_seq, ticker_id, h_prev, c_prev)\n",
        "\n",
        "        # Inverse scale the prediction\n",
        "        min_target, max_target = scalers['target']\n",
        "        prediction = y_pred.flatten()[0] * (max_target - min_target) + min_target\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "E_qd48RM5RFc"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_values = predict_for_stock_over_time(lstm, stock_data, 'AAPL', ticker_mapping, scalers, seq_length)\n",
        "print(f\"Predicted log_returns for AAPL ({len(predicted_values)} values):\")\n",
        "print(predicted_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOkvCE1w5T1D",
        "outputId": "bafcb72c-a1b8-4d85-cf7b-659066b901b5"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted log_returns for AAPL (1 values):\n",
            "[np.float64(-0.10250666080672718)]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}