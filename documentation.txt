LSTM_v1(vanilla).ipynb
Basic Lstm model that predicts stock prices based on closing prices.
With default parameters:
1) input_dim
2) hidden_dim
3) output_dim
4) learning_rate

Now i have yet to add other parameter like:  
1) dropout(regularization)
2) Adam optimizer which works well for time-series
3) sequence length (capture short/long term trends)
4) batch size
5) Bidirectional

i will also implement feature engineering. for now the model is only considering
closing prices but i will add:
1) moving averages (SMA, EMA)
2) trading volume
3) relative strength index (RSI)
4) moving average convergence/divergence (MACD)
5) Bollinger Bands (maybe not sure)


LSTM_v2.ipynb
Mid tier model that predicts stock prices based on closing prices (still).
With new additional parameters:
1) input_dim
2) hidden_dim
3) output_dim
4) learning_rate
5) dropout
6) adam optimiser
7) sequence length (pichle kitne dinon ka data chahiye for training)

*Next step will be implementing feature engineering as i mentioned 
above with maybe batch size implentation

*There is also some issue while training since the loss inc/dec randomly. 
will fix it as well (issue most probably is that weights arent being updated properly)

i tried implementing bi-directional lstm with same param as before. the code works but the accuracy is really bad.
i am thinking to use lstm_v1(vanilla).ipynb file since it is the basic lstm code and then make changes in it again including feature engineering
since this code gave me best stock price prediction, i will also add adam optimiser to adapt to trends.


LSTM_v3.ipynb:
i used the original lstm_v1(vanilla).ipynb code. it is a vanilla lstm model.

**vanilla lstm model:
a vanilla LSTM (Long Short-Term Memory) is the basic version of an LSTM neural network. 
it is a type of Recurrent Neural Network (RNN) specifically designed to learn long-term dependencies
and solve the vanishing gradient problem that basic RNNs face.

i then implemented backpropagation through time (BPTT) and thr weightsare being updated in both the forward pass
and the backward pass. For now i am using stochastic gradient descent (SGD) but now in this code i will implement
ADAM optimiser for better adaptive learning rates for both forward and backward path and additionally 
add dropout rate so that randomly any neuron can be dropped so that model doesnt overfit or underfit.
typically i believe our model should overfit since in my experience the stock prices either follow three stages:
1) uptrend 2) sideways movement 3) downtrend
in all these cases prices dont fluctuate rapidly so overfitting will do the job unless there is some other factors like
news, company's financial report or any other reason which makes the stock prices go up or down rapidly


LSTM_v3_withGraphs.ipynb
i added some graphs in this notebook and fixed sequence error. the model was being trained on single last sequence but in 
def create_sequences we were training for 50 days. because of training on single last sequence, the prediction was starting from 0 
which is abnormal but when fixed (LSTM being trained on 50 sequential days), stock prices prediction was correct. 


LSTM_stock_feature_engineering.ipynb
since our LSTM_v3_withGraphs.ipynb is working correctly with correct backpropagation through time implementation (vanilla)
so now we need to add more input gates to make the model more robust and accurate. Instead of tempering with LSTM_v3_withGraphs.ipynb
i created this new file LSTM_stock_feature_engineering.ipynb where i save the stock data imported from yfinance into <ticker>_data.csv 
then load the csv, perform some feature engineering:
1) Moving averages (10)
   Moving averages (50)
   Moving averages (100)
   Moving averages (200)
2) Relative Strength Index (RSI) for 14 days 
3) Normalized Volume (range 0-1)
4) Bollinger Band Calculation

i then added these features in <ticker>_stock_features.csv
i plotted rsi and Bollinger band graph jus to check if they are working fine

*now the next step is to import this data set first in LSTM_v3_withGraphs.ipynb, normalize each feature (volume is already done).
this way we will have 4/5 input features [closing price, moving avgs, rsi, volume and bollinger band(maybe)]
we will only have to make small changes in LSTM_v3_withGraphs.ipynb specifically:
1) class LSTM
2) def create_sequences
3) def train
4) def predict

LSTM_integration_features.ipynb
This code is a LSTM_v3_withGraphs.ipynb wrapper. i just imported the <ticker>_stock_features.csv and then used the features 
[close price(already implemented), RSI, normalized volume, moving averages, bollinger Bands] as input. so now the LSTM model
is no more vanilla model since now we 5 input gates. 
for the selection of Moving Averages, i chose MA-100 since used to identify medium-term trends and can be used to confirm
or deny the trend identified by shorter or longer MAs Can be used to identify support and resistance levels 
After updating code accordingly, the code is working perfectly. 
i used 100 epochs with learning rate 0.01 and loss was 0.9. although when i was using vanilla lstm or vanilla lstm with BPTT
the accuracy was 0.6 with same parameters but there was only one input gate. if i decrease learning rate to 0.005 and increase epochs 
to 200-300, accuracy of 0.7-0.6 will be easy achievable. 

*next step is to implement more parameters in LSTM_integration_features.ipynb
1) adam optimiser
2) dropout rate (important)
3) batch size
4) Bidirectional lstm (already implemented in BPTT)

*HOW TO RUN THE SETUP*
1)look into LSTM_v1(vanilla).ipynb, LSTM_v2, LSTM_v3_withGraphs (DONT RUN)
2)run LSTM_stock_feature_engineering.ipynb
3)run LSTM_integration_features.ipynb

Another way of predicting is RNNs
